{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoModel, AutoTokenizer, BertModel, BertConfig\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "# import gluonnlp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "GPUIndex = str(\"0\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= GPUIndex\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DefRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded . \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeec6c04f0d54f8b912e8493b021ae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.25\r"
     ]
    }
   ],
   "source": [
    "# Embedding = Embedding.to(device)\n",
    "CandidateNum = 3\n",
    "distance = nn.MSELoss(reduction='none')\n",
    "# distance = nn.CosineEmbeddingLoss(reduction='none')\n",
    "correct, total = 0, 0\n",
    "WordDef_test_src, WordDef_test_tgt = [], []\n",
    "# ModelName = 'bert-base-uncased'\n",
    "# ModelName = 'bert-large-uncased'\n",
    "# ModelName = 'roberta-base'\n",
    "# ModelName = 'sentence-transformers/bert-base-nli-stsb-mean-tokens'\n",
    "# ModelName = '/ckpt/def-bert/GlossBERT/'\n",
    "# ModelName = '/ckpt/def-bert/save/mlm/bert/checkpoint-21605/'\n",
    "# ModelName = '/ckpt/def-bert/save/mlm/sent-bert/checkpoint-2161/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-D[CLS]/'\n",
    "# ModelName = '/ckpt/def-bert/save/D[CLS]-E[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]+W[CLS]-D[CLS]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]+W[CLS]-D[CLS]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]+D[CLS]-E[TGT]/'\n",
    "ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]+D[CLS]-E[TGT]/'\n",
    "# ModelName = './save/WD+DE+WW+WE_best/'\n",
    "\n",
    "Model = AutoModel.from_pretrained(ModelName)\n",
    "# Model = BertModel(BertConfig())\n",
    "\n",
    "Tokenizer = AutoTokenizer.from_pretrained(ModelName)\n",
    "Model.eval()\n",
    "print(\"Loaded . \")\n",
    "Model = nn.DataParallel(Model).to(device)\n",
    "\n",
    "# Defs = []\n",
    "# for w in VocabPOSDefExamDict.keys():\n",
    "#     for p in VocabPOSDefExamDict[w].keys():\n",
    "#         Defs += list(VocabPOSDefExamDict[w][p].keys())\n",
    "# print(len(Defs))\n",
    "\n",
    "# FileObject = open(\"./data/DefRank_easy.txt\", 'r', encoding='utf-8')\n",
    "# FileObject = open(\"./data/DefRank_challenge.txt\", 'r', encoding='utf-8')\n",
    "FileObject = open(\"./data/DefRank_neo.txt\", 'r', encoding='utf-8')\n",
    "\n",
    "pbar = tqdm()\n",
    "for line in FileObject:\n",
    "    line = line.strip().split(' | ')\n",
    "    Word = line[0]; Defs = line[1:]\n",
    "    Word = Tokenizer(Word, add_special_tokens=True, padding=True, return_tensors='pt')\n",
    "    Defs = Tokenizer(Defs, add_special_tokens=True, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        WordEmb = Model(**Word)['last_hidden_state'][:,0,:] # CLS\n",
    "        DefEmb = Model(**Defs)['last_hidden_state'][:,0,:]\n",
    "        WordEmb = WordEmb.repeat(DefEmb.size(0),1)\n",
    "        Distance = distance(WordEmb, DefEmb)\n",
    "        Distance = torch.mean(Distance, dim=1, keepdim=True)\n",
    "        \n",
    "        _, prediction = torch.min(Distance, 0)\n",
    "        correct += (prediction == 0).sum().item()\n",
    "        total += prediction.size(0)\n",
    "        print(np.round(correct*100/total, 2), end='\\r')\n",
    "    pbar.update(1)\n",
    "FileObject.close()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36.37\n",
    "#1 40.76, 26.79 41.16\n",
    "#1 45.75, 25.97, 44.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 40.74, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 41.85?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SenseRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded . \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a991e7122f574d349dabac20d723aa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.02\r"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "distance = nn.MSELoss(reduction='none')\n",
    "# distance = nn.CosineEmbeddingLoss(reduction='none')\n",
    "correct, total = 0, 0\n",
    "# ModelName = 'bert-base-uncased'\n",
    "# ModelName = 'bert-large-uncased'\n",
    "# ModelName = 'roberta-base'\n",
    "# ModelName = 'sentence-transformers/bert-base-nli-stsb-mean-tokens'\n",
    "# ModelName = '/ckpt/def-bert/GlossBERT/'\n",
    "# ModelName = '/ckpt/def-bert/save/mlm/bert/checkpoint-21605/'\n",
    "# ModelName = '/ckpt/def-bert/save/mlm/sent-bert/checkpoint-2161/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-D[CLS]/'\n",
    "# ModelName = '/ckpt/def-bert/save/D[CLS]-E[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]+W[CLS]-D[CLS]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]+W[CLS]-D[CLS]/'\n",
    "ModelName = '/ckpt/def-bert/save/W[CLS]-W[TGT]+D[CLS]-E[TGT]/'\n",
    "# ModelName = '/ckpt/def-bert/save/W[CLS]-E[TGT]+D[CLS]-E[TGT]/'\n",
    "# ModelName = './save/WD+DE+WW+WE_best/'\n",
    "\n",
    "Model = AutoModel.from_pretrained(ModelName)\n",
    "Tokenizer = AutoTokenizer.from_pretrained(ModelName)\n",
    "Model.eval()\n",
    "print(\"Loaded . \")\n",
    "Model = nn.DataParallel(Model).to(device)\n",
    "\n",
    "FileObject = open(\"./data/SenseRank_test.txt\", 'r', encoding='utf-8')\n",
    "Extractor = torch.tensor([0]).unsqueeze(1).expand(-1,10).to(device)\n",
    "\n",
    "pbar = tqdm()\n",
    "for line in FileObject:\n",
    "    line = line.strip().split(' | ')\n",
    "    Word = line[0]; Exam = line[1]; Defs = line[2:]\n",
    "    Word = Tokenizer(Word, add_special_tokens=False, padding=True, return_tensors='pt')\n",
    "    Defs = Tokenizer(Defs, add_special_tokens=True, padding=True, return_tensors='pt')\n",
    "    Exam = Tokenizer(Exam, add_special_tokens=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    idx = (Exam[\"input_ids\"] == Word[\"input_ids\"][:,0].expand(1,Exam[\"input_ids\"].size(1))).nonzero()#[0].unsqueeze(1).expand(-1,512))\n",
    "    wlen = Word[\"input_ids\"].size(1)\n",
    "    with torch.no_grad():\n",
    "        DefEmb = Model(**Defs)['last_hidden_state'][:,0,:]\n",
    "        WordEmb = Model(**Exam)['last_hidden_state']\n",
    "    if len(idx):\n",
    "        idx = idx[0]\n",
    "    else:\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "    WordEmb = torch.mean( WordEmb[idx[0]:idx[0]+1,idx[1]:idx[1]+wlen,:], dim=1)\n",
    "    WordEmb = WordEmb.repeat(DefEmb.size(0),1)\n",
    "    Distance = distance(WordEmb, DefEmb)\n",
    "    Distance = torch.mean(Distance, dim=1, keepdim=True)\n",
    "\n",
    "    _, prediction = torch.min(Distance, 0)\n",
    "    correct += (prediction == 0).sum().item()\n",
    "    total += prediction.size(0)\n",
    "    print(np.round(correct*100/total, 2), end='\\r')\n",
    "#     break\n",
    "    pbar.update(1)\n",
    "FileObject.close()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.8 31.19\n"
     ]
    }
   ],
   "source": [
    "59.37"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
